
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://geevarughesejohn.github.io/llmbook/Chapter%204%3A%20Recurrent%20Models%20and%20Language%20Generation/4.2.2%20The%20Core%20Idea%20of%20Recurrence.html">
      
      
        <link rel="prev" href="4.2.1%20The%20Need%20for%20Sequential%20Processing.html">
      
      
        <link rel="next" href="4.2.3%20Unrolling%20an%20RNN%20Over%20Time.html">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>4.2.2 The Core Idea of Recurrence - From Words to Intelligence: A Complete Guide to Large Language Models</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.342714a4.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#422-the-core-idea-of-recurrence" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="From Words to Intelligence: A Complete Guide to Large Language Models" class="md-header__button md-logo" aria-label="From Words to Intelligence: A Complete Guide to Large Language Models" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            From Words to Intelligence: A Complete Guide to Large Language Models
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              4.2.2 The Core Idea of Recurrence
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="From Words to Intelligence: A Complete Guide to Large Language Models" class="md-nav__button md-logo" aria-label="From Words to Intelligence: A Complete Guide to Large Language Models" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    From Words to Intelligence: A Complete Guide to Large Language Models
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Chapter 1: The Language Modeling Problem  
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Chapter 1: The Language Modeling Problem  
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%201%3A%20The%20Language%20Modeling%20Problem%20%20/1.1%20learning%20objective.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 1: The Language Modeling Problem
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%201%3A%20The%20Language%20Modeling%20Problem%20%20/1.2%20Introduction.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1.2 Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%201%3A%20The%20Language%20Modeling%20Problem%20%20/1.3%20What%20Does%20It%20Mean%20to%20%E2%80%9CModel%E2%80%9D%20Language%3F.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1.3 What Does It Mean to ‚ÄúModel‚Äù Language?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%201%3A%20The%20Language%20Modeling%20Problem%20%20/1.4%20A%20Brief%20History%20of%20Language%20Modeling%3A%20Rules%20%E2%86%92%20Statistics%20%E2%86%92%20Neural%20Nets.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1.4 A Brief History of Language Modeling: Rules ‚Üí Statistics ‚Üí Neural Nets
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%201%3A%20The%20Language%20Modeling%20Problem%20%20/1.5%20Why%20Is%20Modeling%20Language%20So%20Difficult%3F.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1.5 Why Is Modeling Language So Difficult?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%201%3A%20The%20Language%20Modeling%20Problem%20%20/1.6%20Code%20Example%3A%20A%20Tiny%20Predictive%20Language%20Model%20%28with%20N-Grams%29.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1.6 Code Example: A Tiny Predictive Language Model (with N Grams)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%201%3A%20The%20Language%20Modeling%20Problem%20%20/1.7%20Summary.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1.7 Summary
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%201%3A%20The%20Language%20Modeling%20Problem%20%20/1.8%20Key%20Takeaways.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1.8 Key Takeaways
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%201%3A%20The%20Language%20Modeling%20Problem%20%20/1.9%20Quiz%20Exercises.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1.9 Quiz Exercises
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%201%3A%20The%20Language%20Modeling%20Problem%20%20/ngrms.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ngrms
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Chapter 2: Classical NLP Techniques
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Chapter 2: Classical NLP Techniques
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%202%3A%20Classical%20NLP%20Techniques/1%20Introduction%3A%20What%20is%20Classical%20NLP%3F.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1 Introduction: What is Classical NLP?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%202%3A%20Classical%20NLP%20Techniques/2%20Text%20Preprocessing%3A%20Cleaning%20Up%20Language.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2 Text Preprocessing: Cleaning Up Language
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%202%3A%20Classical%20NLP%20Techniques/3%20Why%20Machines%20Need%20Numbers%20for%20clarity%3F.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3 Why Machines Need Numbers for clarity?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%202%3A%20Classical%20NLP%20Techniques/3.1%20The%20Bag-of-Words%20%28BoW%29%20Model.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.1 The Bag of Words (BoW) Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%202%3A%20Classical%20NLP%20Techniques/3.2%20Term%20Frequency%E2%80%93Inverse%20Document%20Frequency%20%28TF-IDF%29.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.2 Term Frequency‚ÄìInverse Document Frequency (TF IDF)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%202%3A%20Classical%20NLP%20Techniques/3.3%20TF-IDF%3A%20Sparse%20Vectors%20and%20High%20Dimensionality.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.3 TF IDF: Sparse Vectors and High Dimensionality
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%202%3A%20Classical%20NLP%20Techniques/4%20Classical%20NLP%20Pipelines.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4 Classical NLP Pipelines
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%202%3A%20Classical%20NLP%20Techniques/5%20Limitations%20of%20Rule-Based%20and%20Statistical%20Methods.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5 Limitations of Rule Based and Statistical Methods
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%202%3A%20Classical%20NLP%20Techniques/E%3AA%20Classical%20Pipeline.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    E:A Classical Pipeline
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%202%3A%20Classical%20NLP%20Techniques/E%3ABoW%20with%20Scikit-learn.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    E:BoW with Scikit learn
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%202%3A%20Classical%20NLP%20Techniques/E%3ATF-IDF.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    E:TF IDF
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%202%3A%20Classical%20NLP%20Techniques/chapter.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Chapter 3: Word Embeddings and Dense Representations
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Chapter 3: Word Embeddings and Dense Representations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/%20Code%20Example%3A%20Using%20Pretrained%20Word%20Embeddings.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
     Code Example: Using Pretrained Word Embeddings
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.1%20Introduction%3A%20From%20Counting%20Words%20to%20Capturing%20Meaning.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 3: Word Embeddings and Dense Representations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.2.1%20What%20Is%20a%20Word%20Embedding%3F.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.2.1 What Is a Word Embedding?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.2.2%20Sparse%20vs.%20Dense%20Representations.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.2.2 Sparse vs. Dense Representations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.2.3%20How%20Embeddings%20Represent%20Similarity.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.2.3 How Embeddings Represent Similarity
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.2.4%20The%20Shape%20of%20Meaning%3A%20Embedding%20Space.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.2.4 The Shape of Meaning: Embedding Space
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.2.5%20A%20Glimpse%20at%20the%20Math.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.2.5 A Glimpse at the Math
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.3%20How%20Embeddings%20Capture%20Meaning.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.3 How Embeddings Capture Meaning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.4.1%20What%20Is%20Word2Vec%3F.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.4.1 What Is Word2Vec?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.4.2%20CBOW%20and%20Skip-Gram%3A%20Two%20Learning%20Strategies.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.4.2 CBOW and Skip Gram: Two Learning Strategies
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.4.3%20Training%20Word2Vec%3A%20How%20the%20Model%20Learns.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.4.3 Training Word2Vec: How the Model Learns
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.4.4%20Negative%20Sampling%20and%20Efficiency%20Tricks.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.4.4 Negative Sampling and Efficiency Tricks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.4.5%20Practical%20Example%3A%20Training%20Word2Vec%20in%20Python.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.4.5 Practical Example: Training Word2Vec in Python
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.4.6%20Strengths%20and%20Limitations%20of%20Word2Vec.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.4.6 Strengths and Limitations of Word2Vec
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.5%20Beyond%20Word2Vec%20%E2%80%93%20The%20Evolution%20of%20Word%20Embeddings.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.5 Beyond Word2Vec ‚Äì The Evolution of Word Embeddings
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.5.1%20Why%20Move%20Beyond%20Word2Vec%3F.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.5.1 Why Move Beyond Word2Vec?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.5.2%20FastText%20%E2%80%93%20Words%20as%20Bags%20of%20Subwords.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.5.2 FastText ‚Äì Words as Bags of Subwords
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.5.3%20GloVe%20%E2%80%93%20Global%20Vectors%20for%20Word%20Representation.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.5.3 GloVe ‚Äì Global Vectors for Word Representation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.5.4%20Comparing%20Word2Vec%2C%20GloVe%2C%20and%20FastText.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.5.4 Comparing Word2Vec, GloVe, and FastText
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/3.6%20Limitations%20of%20Word%20Embeddings%20%E2%80%94%20And%20What%20Comes%20Next.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.6 Limitations of Word Embeddings ‚Äî And What Comes Next
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/Learning%20Objectives.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 3: Word Embeddings and Dense Representations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203%3A%20Word%20Embeddings%20and%20Dense%20Representations/chapter.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Chapter 3E: Introduction to Machine Learning and Neural Networks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Chapter 3E: Introduction to Machine Learning and Neural Networks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter%203E%3A%20Introduction%20to%20Machine%20Learning%20and%20Neural%20Networks/chapter.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Chapter 4: Recurrent Models and Language Generation
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Chapter 4: Recurrent Models and Language Generation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.1%20Introduction%20%E2%80%93%20Why%20Word%20Order%20and%20Memory%20Matter.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.1 Introduction ‚Äì Why Word Order and Memory Matter
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.2.1%20The%20Need%20for%20Sequential%20Processing.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.2.1 The Need for Sequential Processing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    4.2.2 The Core Idea of Recurrence
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="4.2.2%20The%20Core%20Idea%20of%20Recurrence.html" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    4.2.2 The Core Idea of Recurrence
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#422-the-core-idea-of-recurrence" class="md-nav__link">
    <span class="md-ellipsis">
      4.2.2 The Core Idea of Recurrence
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.2.2 The Core Idea of Recurrence">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a-little-math-gently-introduced" class="md-nav__link">
    <span class="md-ellipsis">
      üß† A Little Math (Gently Introduced)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#analogy-reading-a-story" class="md-nav__link">
    <span class="md-ellipsis">
      üìö Analogy: Reading a Story
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-it-matters" class="md-nav__link">
    <span class="md-ellipsis">
      üß© Why It Matters
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.2.3%20Unrolling%20an%20RNN%20Over%20Time.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.2.3 Unrolling an RNN Over Time
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.2.4%20RNN%20in%20Practice%20%E2%80%93%20A%20Step-by-Step%20Example.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.2.4 RNN in Practice ‚Äì A Step by Step Example
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.2.5%3A%20Strengths%20and%20Weaknesses%20of%20Vanilla%20RNNs.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.2.5: Strengths and Weaknesses of Vanilla RNNs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.3%20The%20Problem%20of%20Vanishing%20Gradients.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.3 The Problem of Vanishing Gradients
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.4.1%20Motivation%3A%20Why%20Vanilla%20RNNs%20Need%20Help.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.4.1 Motivation: Why Vanilla RNNs Need Help
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.4.2%20Inside%20the%20LSTM%20Cell.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.4.2 Inside the LSTM Cell
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.4.3%20How%20LSTMs%20Process%20Sequences.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.4.3 How LSTMs Process Sequences
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.4.4%20When%20and%20Why%20to%20Use%20LSTMs.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.4.4 When and Why to Use LSTMs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.5.1%20Motivation%20for%20GRUs.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.5.1 Motivation for GRUs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.5.2%20Inside%20the%20GRU%20Cell.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.5.2 Inside the GRU Cell
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.5.3%20Comparing%20GRU%20and%20LSTM.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.5.3 Comparing GRU and LSTM
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.5.4%20When%20to%20Use%20GRUs.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.5.4 When to Use GRUs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.6.1%3A%20Language%20Generation%20with%20RNNs.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.6.1: Language Generation with RNNs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.6.2%20Training%20a%20Recurrent%20Language%20Model.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.6.2 Training a Recurrent Language Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.6.3%20Sampling%20and%20Generation%20During%20Inference.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.6.3 Sampling and Generation During Inference
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.6.4%20Code%20Example%20%E2%80%93%20Generating%20Text%20with%20GRU.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.6.4 Code Example ‚Äì Generating Text with GRU
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="4.6.5%20Challenges%20and%20Limitations%20of%20RNN-based%20Generation.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.6.5 Challenges and Limitations of RNN based Generation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="RNN.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RNN
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#422-the-core-idea-of-recurrence" class="md-nav__link">
    <span class="md-ellipsis">
      4.2.2 The Core Idea of Recurrence
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.2.2 The Core Idea of Recurrence">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a-little-math-gently-introduced" class="md-nav__link">
    <span class="md-ellipsis">
      üß† A Little Math (Gently Introduced)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#analogy-reading-a-story" class="md-nav__link">
    <span class="md-ellipsis">
      üìö Analogy: Reading a Story
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-it-matters" class="md-nav__link">
    <span class="md-ellipsis">
      üß© Why It Matters
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



  <h1>4.2.2 The Core Idea of Recurrence</h1>

<h2 id="422-the-core-idea-of-recurrence"><strong>4.2.2 The Core Idea of Recurrence</strong></h2>
<p>At the heart of a Recurrent Neural Network (RNN) is a simple but powerful idea: <strong>what you‚Äôve already seen should help you understand what comes next</strong>.</p>
<p>Let‚Äôs break that down.</p>
<p>In a standard feedforward neural network, you give the model an input, it processes that input, and then it produces an output. Done. It doesn‚Äôt remember anything about what came before. That‚Äôs fine for tasks where each input is independent‚Äîlike identifying whether an image contains a cat or not‚Äîbut it doesn‚Äôt work well for language, where meaning <strong>depends on history</strong>.</p>
<p>RNNs fix this by introducing a concept called a <strong>hidden state</strong>. Think of it as the model‚Äôs <strong>memory</strong>. At each step in a sequence, the RNN updates this memory based on two things:</p>
<ol>
<li>The <strong>current input</strong> (the word it‚Äôs reading now)</li>
<li>The <strong>previous hidden state</strong> (its memory from the past)</li>
</ol>
<p>Together, these allow the RNN to form a new understanding of the sentence so far.</p>
<hr />
<h3 id="a-little-math-gently-introduced">üß† A Little Math (Gently Introduced)</h3>
<p>Let‚Äôs say we‚Äôre processing a sentence word by word. At time step <code>t</code>, the RNN receives:</p>
<ul>
<li>The input word vector: $x_t$</li>
<li>The previous hidden state: $h_{t-1}$</li>
</ul>
<p>It then computes the new hidden state $h_t$ like this:</p>
<p>$$
h_t = \tanh(W \cdot x_t + U \cdot h_{t-1} + b)
$$</p>
<p>Here‚Äôs what that means:</p>
<ul>
<li>$W$ is a weight matrix that transforms the input</li>
<li>$U$ is another matrix that transforms the hidden state</li>
<li>$b$ is a bias term</li>
<li>$\tanh$ is the activation function that squashes values between ‚Äì1 and 1</li>
</ul>
<p>Each time the RNN reads a new word, it blends that word with its current memory, updates its hidden state, and passes it forward.</p>
<p>You can visualize it like this:</p>
<pre><code>x_t ‚îÄ‚îÄ‚ñ∂[ RNN Cell ]‚îÄ‚îÄ‚ñ∂ h_t
       ‚ñ≤       ‚îÇ
       ‚îÇ       ‚ñº
     h_{t-1}  Output
</code></pre>
<p>Each <strong>RNN Cell</strong> has a loop inside it‚Äîthis is what allows it to carry memory from one step to the next. It‚Äôs why we call it <em>recurrent</em>.</p>
<hr />
<h3 id="analogy-reading-a-story">üìö Analogy: Reading a Story</h3>
<p>Imagine reading a mystery novel. As each new clue is revealed, you update your mental model of who might be the culprit. That internal model‚Äîthe accumulation of everything you‚Äôve read so far‚Äîis like the RNN‚Äôs hidden state. Each new piece of information (a sentence or paragraph) modifies your understanding just a bit. You don‚Äôt forget everything that came before‚Äîyou build on it.</p>
<hr />
<h3 id="why-it-matters">üß© Why It Matters</h3>
<p>This structure allows the RNN to <strong>capture patterns over time</strong>. It can learn that ‚ÄúThe cat sat on the‚Äù is likely to be followed by ‚Äúmat,‚Äù or that the phrase ‚ÄúI am feeling very‚Äù could lead to ‚Äúhappy,‚Äù ‚Äúsad,‚Äù or ‚Äútired‚Äù depending on the context.</p>
<p>But while this idea of recurrence is powerful, it's not without flaws. As sequences grow longer, the RNN‚Äôs memory begins to fade. It becomes harder for the model to carry meaningful signals across many steps‚Äîa problem we‚Äôll explore in a later section on <strong>vanishing gradients</strong>.</p>
<p>Before we get there, let‚Äôs first look at how RNNs work when you process <strong>an entire sentence</strong>, one word at a time. That‚Äôs what we‚Äôll cover next in <strong>4.2.3: Unrolling an RNN Over Time</strong>.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.sections", "content.code.copy"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
    
  </body>
</html>