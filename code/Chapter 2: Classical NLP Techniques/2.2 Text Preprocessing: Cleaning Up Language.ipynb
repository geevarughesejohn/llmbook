{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "618d0cef",
   "metadata": {},
   "source": [
    "### Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f624ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python is great!'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Python is Great!\"\n",
    "text.lower()  # Output: \"python is great!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37bb6ff",
   "metadata": {},
   "source": [
    "### Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ae9396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello world Hows everything'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "text = \"Hello, world! How's everything?\"\n",
    "text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffd7eab",
   "metadata": {},
   "source": [
    "### Removing Stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e76796e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simple', 'sentence', '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure required NLTK resources are installed\n",
    "import nltk\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(text.lower())\n",
    "filtered = [word for word in tokens if word not in stopwords.words('english')]\n",
    "filtered\n",
    "# Output: ['simple', 'sentence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63ecbb5",
   "metadata": {},
   "source": [
    "### Word Tokenization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240524cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3a9e192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural', 'Language', 'Processing', 'is', 'fun', '!']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"Natural Language Processing is fun!\"\n",
    "tokens = word_tokenize(text)\n",
    "tokens\n",
    "# Output: ['Natural', 'Language', 'Processing', 'is', 'fun', '!']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6085ec",
   "metadata": {},
   "source": [
    "### Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3ba4bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello world.', 'NLP is interesting.', \"Let's learn more!\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "paragraph = \"Hello world. NLP is interesting. Let's learn more!\"\n",
    "sentences = sent_tokenize(paragraph)\n",
    "sentences\n",
    "# Output: ['Hello world.', 'NLP is interesting.', \"Let's learn more!\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365b8f3a",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba7381c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run', 'runner', 'ran']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "words = [\"running\", \"runner\", \"ran\"]\n",
    "stems = [stemmer.stem(word) for word in words]\n",
    "stems\n",
    "# Output: ['run', 'runner', 'ran']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c49688d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install --quiet nltk\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"running\", pos=\"v\")  # Output: 'run'\n",
    "lemmatizer.lemmatize(\"better\", pos=\"a\")   # Output: 'good'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b7e6c",
   "metadata": {},
   "source": [
    "### Part-of-Speech (POS) Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "235e6cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet nltk\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "# Download both possible tagger resources for compatibility\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger_eng', quiet=True)\n",
    "\n",
    "sentence = \"The quick brown fox jumps over the lazy dog\"\n",
    "tokens = word_tokenize(sentence)\n",
    "pos_tags = pos_tag(tokens)\n",
    "# Output: [('The', 'DT'), ('quick', 'JJ'), ..., ('dog', 'NN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c46c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
