
## **3.2.3 How Embeddings Represent Similarity**

One of the most powerful and exciting features of word embeddings is that they make it possible to **measure how similar two words areâ€”not by spelling or frequency, but by meaning.**

This is something that classical NLP methods couldnâ€™t do. In Bag-of-Words or TF-IDF, the words `"happy"` and `"joyful"` are just two separate entries in a list. Thereâ€™s no mathematical reason to treat them as similar, even if they often appear in the same kinds of texts.

But with word embeddings, we get something different. Words are not just symbols anymoreâ€”theyâ€™re **points in space**, and that changes everything.

---

### ğŸ§­ Similarity as Distance in Space

Letâ€™s say each word is represented by a vector: a list of numbers like this:

```python
"happy"   â†’ [0.62, -0.14, 0.55, ..., 0.09]  
"joyful"  â†’ [0.60, -0.18, 0.58, ..., 0.12]
"sad"     â†’ [-0.45,  0.27, -0.32, ..., 0.78]
```

Now, we can use simple geometry to ask:

> How close are these points to each other?

Words that are **similar in meaning** will have **vectors that point in the same direction**, or are located near one another in the vector space.

---

### ğŸ“ Cosine Similarity: A Common Metric

To measure how â€œcloseâ€ two vectors are, we often use a technique called **cosine similarity**. Donâ€™t worryâ€”the name sounds more complicated than it really is.

Cosine similarity looks at the **angle between two vectors**. If they point in the same direction, the angle is small, and the cosine value is close to `1`â€”meaning the words are similar. If they point in opposite directions, the cosine is close to `-1`â€”meaning theyâ€™re dissimilar.

You donâ€™t need to calculate this by hand. But conceptually, hereâ€™s how it works:

* `"happy"` and `"joyful"` â†’ cosine similarity â‰ˆ `0.95` â†’ **very similar**
* `"happy"` and `"sad"` â†’ cosine similarity â‰ˆ `-0.2` â†’ **very different**
* `"happy"` and `"dog"` â†’ cosine similarity â‰ˆ `0.1` â†’ **mostly unrelated**

This is what makes embeddings **semantically meaningful**: the numbers are not arbitrary. They reflect the **actual behavior of words in language**.

---

### ğŸ§  Understanding Through Context

Why do similar words end up with similar vectors?

Because embeddings are learned by observing the **contexts** in which words appear. If two words appear in similar contexts, theyâ€™re likely to mean similar things.

For example:

* `"happy"` might appear in sentences like:

  * â€œShe felt happy after the exam.â€
  * â€œIt was a happy day for everyone.â€
* `"joyful"` might appear in:

  * â€œHe looked joyful at the celebration.â€
  * â€œThe joyful news spread quickly.â€

The words around themâ€”like â€œfelt,â€ â€œcelebration,â€ â€œnews,â€ â€œdayâ€â€”are often shared or similar. This shared context pulls their vectors closer together during training.

This idea is based on something called the **distributional hypothesis**:

> *â€œYou shall know a word by the company it keeps.â€* â€” J.R. Firth (1957)

In short: **meaning emerges from usage**.

---

### ğŸ“ Words in Clusters

If you could see embeddings in 2D or 3D space (which weâ€™ll do later using tools like t-SNE or PCA), youâ€™d notice something amazing:

* Words form **clusters** based on themes:
  â€œcatâ€, â€œdogâ€, â€œhamsterâ€ â†’ pets
  â€œParisâ€, â€œBerlinâ€, â€œRomeâ€ â†’ European cities
  â€œrunâ€, â€œwalkâ€, â€œjogâ€ â†’ physical actions

* Words also form **semantic gradients**â€”smooth transitions across related meanings.

This is a huge leap from earlier methods. Weâ€™re not just seeing which words appear together; weâ€™re seeing **how their meanings relate to one another in space.**

---

### âœ¨ Why It Matters

Once we can measure similarity between words, we can:

* **Find synonyms automatically**
* **Group documents by meaning**
* **Improve search results** (e.g., searching for â€œdoctorâ€ might also match â€œphysicianâ€)
* **Power neural networks** for tasks like sentiment analysis, question answering, and machine translation

This is the beating heart of modern NLP: instead of treating words as symbols, we treat them as **concepts with geometry**.

